{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1r14fVR_LdK88VN_zs7QZeKkgTF-h8qjq",
      "authorship_tag": "ABX9TyMC6noO7JUdtq+KsUZJua5C"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHxQCOG232Kv"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
        "\n",
        "# Write the Streamlit app to a file\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "import streamlit as st\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the VGG19 model\n",
        "model = VGG19(weights='imagenet')\n",
        "\n",
        "def model_predict(img_path, model):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model.predict(x)\n",
        "    return preds\n",
        "\n",
        "def main():\n",
        "    st.title(\"Image Classification with VGG19 Model\")\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type=\"jpg\")\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        st.image(uploaded_file, caption=\"Uploaded Image.\", use_column_width=True)\n",
        "        st.write(\"\")\n",
        "        st.write(\"Classifying...\")\n",
        "\n",
        "        # Save the uploaded image temporarily\n",
        "        temp_image_path = \"temp_image.jpg\"\n",
        "        with open(temp_image_path, \"wb\") as temp_image:\n",
        "            temp_image.write(uploaded_file.read())\n",
        "\n",
        "        # Make prediction\n",
        "        preds = model_predict(temp_image_path, model)\n",
        "        decoded_preds = decode_predictions(preds, top=1)[0]\n",
        "\n",
        "        st.write(f\"Prediction: {decoded_preds[0][1]}, Confidence: {decoded_preds[0][2]:.2%}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    \"\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "f6luHo_v50RV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff83433a-5b1c-41bf-cd04-172428d53c7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.82.111.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "GufX0vZW36y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f84430f-7d03-4829-8a9c-f703756cc98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l[..................] / rollbackFailedOptional: verb npm-session 976dd704e645c7b\u001b[0m\u001b[K\r[..................] / rollbackFailedOptional: verb npm-session 976dd704e645c7b\u001b[0m\u001b[K\r[..................] / rollbackFailedOptional: verb npm-session 976dd704e645c7b\u001b[0m\u001b[K\r\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.82.111.50:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.164s\n",
            "your url is: https://four-coats-grab.loca.lt\n",
            "2024-01-28 12:22:32.538913: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-28 12:22:32.538972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-28 12:22:32.540667: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-28 12:22:34.083147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-28 12:22:36.750327: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574710816/574710816 [==============================] - 5s 0us/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "35363/35363 [==============================] - 0s 0us/step\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "1/1 [==============================] - 0s 155ms/step\n",
            "1/1 [==============================] - 0s 221ms/step\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x784e2e095ab0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 151ms/step\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x784e2e097e20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 151ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "58Tpe0SbBCs5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}